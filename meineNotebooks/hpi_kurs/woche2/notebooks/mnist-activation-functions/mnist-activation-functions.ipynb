{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.8 - Aktivierungsfunktionen_Praxis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPsgVD8iEITE",
        "colab_type": "text"
      },
      "source": [
        "#### Importieren der notwendigen Bibliotheken\n",
        "\n",
        "Wir wollen die Tensorflow Version 2.0 verwenden und geben diese daher spezifisch an. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anAbuY1-dzbZ",
        "colab_type": "code",
        "outputId": "2073fc22-8491-4828-d73b-9b299a45a176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYKdhdArMixR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BI2UvBJEVM8",
        "colab_type": "text"
      },
      "source": [
        "#### Laden des MNIST Datensatzes\n",
        "\n",
        "Als Erstes wollen wir den Datensatz wie im Video \"Laden und Bearbeiten des MNIST Datensatz\" laden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrkKkPW2OIfB",
        "colab_type": "code",
        "outputId": "3e4a144f-f5f5-43eb-8d07-78317dcad5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras. \\\n",
        "  datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x_4ihQfEeNP",
        "colab_type": "text"
      },
      "source": [
        "Wir errinnern uns, dass die Pixelwerte noch nicht in normaliserter Form vorliegen. Wir normalisieren diese also zunächst indem wir durch den maximalen Pixelwert 255 teilen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6onrRWeHOV8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQlp8ZldEpPG",
        "colab_type": "text"
      },
      "source": [
        "Zuletzt hatten wir noch das Problem, dass die Labels des Datensatzes einfach nur Zahlen waren.\n",
        "- Das Bild der handgeschriebenen 5 hat das Label `5`.\n",
        "- Wir hätten in diesem Fall jedoch gerne den Vektor `[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]` als Label, welcher der von unserem Netz gewünschten Ausgabe entspricht. Dieser Vektor hat nur an Stelle 5 (beginnend bei 0) eine 1.\n",
        "\n",
        "Für detailliertere Erklärungen sei an dieser Stelle wieder auf das Video \"Laden und Bearbeiten des MNIST Datensatzes\" verwiesen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbkCCvu8Px1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_classes = 10\n",
        "train_vec_labels = keras.utils.to_categorical(train_labels, total_classes)\n",
        "test_vec_labels = keras.utils.to_categorical(test_labels, total_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TSPdilFE6eA",
        "colab_type": "text"
      },
      "source": [
        "#### Entwurf der Netze\n",
        "\n",
        "Nun haben wir die Eingabedaten normalisiert und die Labels als Vektoren vorliegen. Wir können also endlich anfangen die Netze für die Erkennung der handgeschriebenen Zahlen zu bauen! :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4gc7lPAE_2A",
        "colab_type": "text"
      },
      "source": [
        "Wir wollen dafür verschiedene, sehr einfache Netze mit 3 Schichten definieren (Eingabelayer, Hidden Layer und Ausgabelayer):\n",
        "- Als **Input-Layer** verwenden wir einen `keras.layers.Flatten` Layer, der die 28x28 Matrizen, die wir als Eingaben erhalten auf $28\\cdot 28 = 784$ Neuronen verteilt\n",
        "- Als nächstes verwenden wir für den **Hidden-Layer** einen `keras.layers.Dense` Layer mit 128 Neuronen, wobei wir 128 als eine gute Anzahl empfinden\n",
        "- Als **Output-Layer** verwenden wir einen `keras.layers.Dense` Layer mit 10 Neuronen, da wir 10 Klassen (Ziffern von 0-9) erkennen wollen\n",
        "\n",
        "Wir definieren die einzelnen Netze mit den unterschiedlichen Aktivierungsfunktionen, um diese anschließend miteinander vergleichen zu können.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEvwJtk7Oppm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_no_activation = keras.Sequential([\n",
        "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
        "#     keras.layers.Dense(128), # , activation='sigmoid'),\n",
        "#     keras.layers.Dense(10), #, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "model_relu = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_linear = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='linear'),\n",
        "    keras.layers.Dense(10, activation='linear')\n",
        "])\n",
        "\n",
        "model_sigmoid = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='sigmoid'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_tanh = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='tanh'),\n",
        "    keras.layers.Dense(10, activation='tanh')\n",
        "])\n",
        "\n",
        "models = [model_relu, model_linear,\n",
        "          model_sigmoid,model_tanh]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsruqM_GFF6R",
        "colab_type": "text"
      },
      "source": [
        "#### Kompilieren der Netze\n",
        "\n",
        "Nach dem wir unsere Netze definiert haben, müssen wir sie *kompilieren*, bevor wir mit dem Training beginnen können.\n",
        "\n",
        "In diesem Schritt legen wir wichtige Parameter für die Trainingsphase fest:\n",
        "- Der **Optimizer** ist der im Training verwendete Lernalgorithmus zur Verbesserung des Netzes. In der letzen Woche haben wir ja bereits *Gradient Descent* und dessen Optimierung *Stochastic Gradient Descent* (SGD, siehe *Deep Dive: Backpropagation*) kennengelernt.\n",
        "- Der **Loss** ist die verwendete Kostenfunktion. Ziel während des Trainings ist es, diese zu minimieren. Wir haben in Woche 1 bereits die Quadratische Fehlerfunktion (*Squared Error*) kennengelernt.\n",
        "- Die **Metrics** sind die während des Trainings ausgewerteten Metrics. Bei allen Klassifikationsproblemen interessiert uns hier die `\"accuracy\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEVWjCegFLkB",
        "colab_type": "text"
      },
      "source": [
        "In diesem Beispiel verwenden wir \n",
        "- Den *Stochastic Gradient Descent* (`\"sgd\"`) Lernalgorithmus als unseren Optimizer.\n",
        "- Die `\"mean_squared_error\"` Kostenfunktion, welche im Vergleich zur normalen *Squared Error* Kostenfunktion nicht die Summe, sondern den Mittelwert der Fehler der Ausgabeneuronen berechnet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjC8UAqUOyZ6",
        "colab_type": "code",
        "outputId": "cb301dee-294d-4936-fcef-ec9437c28076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[\n",
        "  model.compile(\n",
        "      optimizer='sgd',\n",
        "      loss='mean_squared_error',\n",
        "      metrics=['accuracy']\n",
        "  ) for model in models\n",
        "]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoZmTqF8FSpa",
        "colab_type": "text"
      },
      "source": [
        "#### Trainieren der Netze\n",
        "\n",
        "Jetzt können wir endlich unser Netz tranieren. Dazu verwenden wir die `fit` Methode und übergeben unsere Trainingsbilder als Eingaben mit den dazugehörigen Labels als gewünschte Ausgaben. Die Anzahl der `epochs` gibt an, wie oft das Netz das gesamte Trainingsset zu sehen bekommt. Erhöhen wir die Anzahl der Epochen lassen wir unser Netz länger lernen.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QDK4o68O71J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7584268-dea1-4beb-a15a-4d4cde6e7117"
      },
      "source": [
        "epochs=15\n",
        "[\n",
        " model.fit(\n",
        "    train_images,\n",
        "    train_vec_labels,\n",
        "    epochs=epochs,\n",
        "    verbose=True\n",
        "  ) for model in models\n",
        "]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.1043 - accuracy: 0.2860\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0783 - accuracy: 0.5271\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0679 - accuracy: 0.6165\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0587 - accuracy: 0.6838\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0516 - accuracy: 0.7475\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0463 - accuracy: 0.7878\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0423 - accuracy: 0.8102\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0391 - accuracy: 0.8244\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0366 - accuracy: 0.8353\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0345 - accuracy: 0.8434\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0329 - accuracy: 0.8501\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0315 - accuracy: 0.8562\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0303 - accuracy: 0.8608\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0292 - accuracy: 0.8644\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0283 - accuracy: 0.8683\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.0849 - accuracy: 0.6434\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0535 - accuracy: 0.7936\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0486 - accuracy: 0.8165\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0462 - accuracy: 0.8278\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0447 - accuracy: 0.8334\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0437 - accuracy: 0.8375\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0429 - accuracy: 0.8413\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0424 - accuracy: 0.8433\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0419 - accuracy: 0.8447\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0415 - accuracy: 0.8457\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0412 - accuracy: 0.8471\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0410 - accuracy: 0.8479\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0408 - accuracy: 0.8491\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0406 - accuracy: 0.8490\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0404 - accuracy: 0.8499\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1098 - accuracy: 0.1510\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0883 - accuracy: 0.3308\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0871 - accuracy: 0.4073\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0858 - accuracy: 0.4543\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0843 - accuracy: 0.4974\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0827 - accuracy: 0.5212\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0809 - accuracy: 0.5414\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0790 - accuracy: 0.5607\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0769 - accuracy: 0.5766\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0748 - accuracy: 0.5882\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0727 - accuracy: 0.6048\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0706 - accuracy: 0.6184\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0685 - accuracy: 0.6300\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0666 - accuracy: 0.6431\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0647 - accuracy: 0.6579\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0809 - accuracy: 0.6331\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0551 - accuracy: 0.7969\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0495 - accuracy: 0.8287\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0463 - accuracy: 0.8443\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0439 - accuracy: 0.8556\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0419 - accuracy: 0.8648\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0403 - accuracy: 0.8721\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0388 - accuracy: 0.8783\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0374 - accuracy: 0.8838\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0362 - accuracy: 0.8879\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0351 - accuracy: 0.8922\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0340 - accuracy: 0.8956\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0331 - accuracy: 0.8988\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0323 - accuracy: 0.9020\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0315 - accuracy: 0.9040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.callbacks.History at 0x7f5310578710>,\n",
              " <tensorflow.python.keras.callbacks.History at 0x7f53104683c8>,\n",
              " <tensorflow.python.keras.callbacks.History at 0x7f53103a10b8>,\n",
              " <tensorflow.python.keras.callbacks.History at 0x7f53102d1b70>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sui4vaiHFvzd",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluieren der Netze\n",
        "\n",
        "Bisher hat die Netze nur Trainingsbilder gesehen und damit gelernt. Ziel ist es, mit unseren Netzen, neue Bilder von handgeschriebenen Ziffern zu erkennen. Dafür gibt es die Testdaten, mit denen wir unsere Netze nun auf die Genauigkeit bei ungesehenen Daten überprüfen wollen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeujdy_fU0rl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fe624836-5892-475b-c8ce-9fdc636fe422"
      },
      "source": [
        "_, result_relu = model_relu.evaluate(test_images, test_vec_labels)\n",
        "_, result_linear = model_linear.evaluate(test_images, test_vec_labels)\n",
        "_, result_sigmoid = model_sigmoid.evaluate(test_images, test_vec_labels)\n",
        "_, result_tanh = model_tanh.evaluate(test_images, test_vec_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 95us/sample - loss: 0.0268 - accuracy: 0.8791\n",
            "10000/10000 [==============================] - 1s 92us/sample - loss: 0.0400 - accuracy: 0.8599\n",
            "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0633 - accuracy: 0.6645\n",
            "10000/10000 [==============================] - 1s 89us/sample - loss: 0.0307 - accuracy: 0.9108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFHs3Qw3FeS0",
        "colab_type": "text"
      },
      "source": [
        "#### Übersichliche Darstellung der Ergebnisse\n",
        "\n",
        "Die Darstellung der Ergebnisse mit PrettyTable dient lediglich der Übersichtlichkeit und ist für den Kurs an dieser Stelle nicht weiter wichtig."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hocTWrYaWBQp",
        "colab_type": "code",
        "outputId": "f7b97e22-ac96-46d3-b893-07fa0158ad1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "tbl = PrettyTable()\n",
        "tbl.field_names = [\"Activation function\", f\"Accurracy (after {epochs} epochs)\"]\n",
        "tbl.add_row([\"Tanh\", result_tanh])\n",
        "tbl.add_row([\"model_relu\", result_relu])\n",
        "tbl.add_row([\"Linear\", result_linear])\n",
        "tbl.add_row([\"Sigmoid\", result_sigmoid])\n",
        "print(tbl)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------+-----------------------------+\n",
            "| Activation function | Accurracy (after 15 epochs) |\n",
            "+---------------------+-----------------------------+\n",
            "|         Tanh        |            0.9108           |\n",
            "|      model_relu     |            0.8791           |\n",
            "|        Linear       |            0.8599           |\n",
            "|       Sigmoid       |            0.6645           |\n",
            "+---------------------+-----------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
