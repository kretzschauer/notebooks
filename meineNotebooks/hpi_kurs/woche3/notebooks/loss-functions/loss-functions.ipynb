{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.6.2 - Paxis Loss Functions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcaAys-RFK1H",
        "colab_type": "text"
      },
      "source": [
        "# Praxis - Loss Functions\n",
        "\n",
        "In diesem Notebook werden verschiedene Loss Functions anhand des MNIST Datensatzes verglichen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anAbuY1-dzbZ",
        "colab_type": "code",
        "outputId": "defa8f5a-60b4-4718-8bf7-12c7af021434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "%tensorflow_version 2.x # Command für Google Colab für Tensorflow 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x # Command für Google Colab für Tensorflow 2`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYKdhdArMixR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVw0FcWMFWJL",
        "colab_type": "text"
      },
      "source": [
        "## Laden des MNIST Datensatzes\n",
        "\n",
        "Wie aus der Vorwoche bekannt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrkKkPW2OIfB",
        "colab_type": "code",
        "outputId": "f13d31a3-3f57-48b4-ae65-5ec0ae49ae45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras \\\n",
        "  .datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko1WgcnHFc36",
        "colab_type": "text"
      },
      "source": [
        "#### Hier werden die MNIST Daten normalisiert, dass diese nur noch als Float von 0 bis 1 gespeichert werden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6onrRWeHOV8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI4GOesYFlQK",
        "colab_type": "text"
      },
      "source": [
        "## Definition der Modelle \n",
        "\n",
        "Die Modelle können über die Funktion get_model() erzeugt werden und bestehn aus 2 Dense Layers mit Relu und Sigmoid Funktion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEvwJtk7Oppm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  return keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "model_mse = get_model() # Modell mit Mean Squared Error Loss\n",
        "model_cce =  get_model() # Modell mit Categorical Crossentropy\n",
        "model_scce = get_model() # Modell mit Sparse Categorical Crossentropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlusPtyTGSZJ",
        "colab_type": "text"
      },
      "source": [
        "## Kompilieren der Modelle\n",
        "\n",
        "Für jedes der Modelle wird Stochastic Gradient Descent als Optimizer verwendet und die jeweils zum Modell passende Loss Funktion\n",
        "\n",
        "Dies wird in der `model.compile()` Funktion festgelegt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjC8UAqUOyZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = 'sgd'\n",
        "\n",
        "model_mse.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='mean_squared_error',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model_cce.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model_scce.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-uJ3o-hGp3V",
        "colab_type": "text"
      },
      "source": [
        "## Trainiern der Modelle\n",
        "\n",
        "Dabei werden die Trainigsergebnisse in der history List gespeichert. \n",
        "\n",
        "Für das Training mit der Sparse Categorical Crossentropy müssen die Daten nicht geändert weden. Deswegen kann hier schon mit `model.fit()` trainiert werden. Dabei wird gleich ein Validierungsdatensatz festgelegt.\n",
        "\n",
        "Die anderen beiden Modell werden der models List hinzugefügt, um diese Trainieren zu können. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKT-Fn5-GsSg",
        "colab_type": "code",
        "outputId": "cc63b78a-40b9-44bb-a175-e57eb8baedb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "epochs=15 # Festlegung von 15 Trainigsepochen\n",
        "history = [model_scce.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=epochs,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    verbose=True)\n",
        "]\n",
        "models = [model_mse, model_cce]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.8422 - accuracy: 0.7997 - val_loss: 0.3740 - val_accuracy: 0.9018\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3540 - accuracy: 0.9020 - val_loss: 0.3033 - val_accuracy: 0.9161\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3019 - accuracy: 0.9147 - val_loss: 0.2689 - val_accuracy: 0.9235\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2725 - accuracy: 0.9233 - val_loss: 0.2495 - val_accuracy: 0.9300\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2513 - accuracy: 0.9287 - val_loss: 0.2290 - val_accuracy: 0.9346\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2338 - accuracy: 0.9338 - val_loss: 0.2187 - val_accuracy: 0.9366\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2190 - accuracy: 0.9378 - val_loss: 0.2040 - val_accuracy: 0.9423\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2057 - accuracy: 0.9417 - val_loss: 0.1947 - val_accuracy: 0.9437\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1940 - accuracy: 0.9452 - val_loss: 0.1861 - val_accuracy: 0.9467\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1834 - accuracy: 0.9486 - val_loss: 0.1758 - val_accuracy: 0.9480\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1739 - accuracy: 0.9505 - val_loss: 0.1666 - val_accuracy: 0.9505\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1654 - accuracy: 0.9533 - val_loss: 0.1643 - val_accuracy: 0.9512\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1576 - accuracy: 0.9552 - val_loss: 0.1558 - val_accuracy: 0.9536\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1504 - accuracy: 0.9576 - val_loss: 0.1513 - val_accuracy: 0.9549\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1439 - accuracy: 0.9597 - val_loss: 0.1445 - val_accuracy: 0.9573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FnqQk4kHQxp",
        "colab_type": "text"
      },
      "source": [
        "### Umwandlung der Labels in Categorical Labels \n",
        "(mehr dazu am Ende des Notebooks) \n",
        "\n",
        "Diese werden für das Training mit den anderen Loss Functions benötigt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbkCCvu8Px1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_train_labels = keras.utils.to_categorical(train_labels, 10)\n",
        "_test_labels = keras.utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QDK4o68O71J",
        "colab_type": "code",
        "outputId": "bb9a7ec7-b031-4d49-f2cb-e546b0bbc0bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Trainieren der anderen beiden Modelle\n",
        "history += [model.fit(train_images, _train_labels, epochs=epochs, validation_data=(test_images, _test_labels), verbose=True) for model in models]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0998 - accuracy: 0.3932 - val_loss: 0.0796 - val_accuracy: 0.5636\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0729 - accuracy: 0.6006 - val_loss: 0.0654 - val_accuracy: 0.6545\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0608 - accuracy: 0.6780 - val_loss: 0.0552 - val_accuracy: 0.7118\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0526 - accuracy: 0.7393 - val_loss: 0.0484 - val_accuracy: 0.7775\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0467 - accuracy: 0.7936 - val_loss: 0.0433 - val_accuracy: 0.8209\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0423 - accuracy: 0.8205 - val_loss: 0.0394 - val_accuracy: 0.8396\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0388 - accuracy: 0.8339 - val_loss: 0.0363 - val_accuracy: 0.8530\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0361 - accuracy: 0.8435 - val_loss: 0.0340 - val_accuracy: 0.8621\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0340 - accuracy: 0.8509 - val_loss: 0.0320 - val_accuracy: 0.8669\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0323 - accuracy: 0.8567 - val_loss: 0.0305 - val_accuracy: 0.8718\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0308 - accuracy: 0.8612 - val_loss: 0.0291 - val_accuracy: 0.8743\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0296 - accuracy: 0.8651 - val_loss: 0.0280 - val_accuracy: 0.8772\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0286 - accuracy: 0.8685 - val_loss: 0.0270 - val_accuracy: 0.8800\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0277 - accuracy: 0.8712 - val_loss: 0.0262 - val_accuracy: 0.8816\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0269 - accuracy: 0.8738 - val_loss: 0.0254 - val_accuracy: 0.8837\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.8769 - accuracy: 0.7818 - val_loss: 0.3862 - val_accuracy: 0.8966\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3586 - accuracy: 0.9016 - val_loss: 0.3081 - val_accuracy: 0.9121\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3068 - accuracy: 0.9144 - val_loss: 0.2816 - val_accuracy: 0.9213\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2766 - accuracy: 0.9225 - val_loss: 0.2557 - val_accuracy: 0.9279\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2541 - accuracy: 0.9291 - val_loss: 0.2375 - val_accuracy: 0.9333\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2352 - accuracy: 0.9336 - val_loss: 0.2194 - val_accuracy: 0.9371\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2187 - accuracy: 0.9389 - val_loss: 0.2102 - val_accuracy: 0.9396\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2041 - accuracy: 0.9433 - val_loss: 0.1986 - val_accuracy: 0.9452\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1914 - accuracy: 0.9463 - val_loss: 0.1857 - val_accuracy: 0.9478\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1798 - accuracy: 0.9501 - val_loss: 0.1742 - val_accuracy: 0.9501\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1694 - accuracy: 0.9529 - val_loss: 0.1711 - val_accuracy: 0.9515\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1604 - accuracy: 0.9548 - val_loss: 0.1619 - val_accuracy: 0.9546\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1518 - accuracy: 0.9576 - val_loss: 0.1526 - val_accuracy: 0.9556\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1444 - accuracy: 0.9598 - val_loss: 0.1448 - val_accuracy: 0.9599\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1374 - accuracy: 0.9622 - val_loss: 0.1404 - val_accuracy: 0.9606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G3smAfhHh-z",
        "colab_type": "text"
      },
      "source": [
        "## Plotten der Ergebnisse mit Matplotlib\n",
        "\n",
        "Über `plt.plot` werden die einzelnen Ergebnisse der Modelle in verschiedenen Farben eingebunden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hocTWrYaWBQp",
        "colab_type": "code",
        "outputId": "331cd12e-4e29-4b03-be23-b6a4638cff8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "def plot_learning_curve(ylim=0.6):\n",
        "    plt.figure()\n",
        "    plt.title(\"accuracy comparison\")\n",
        "    axes = plt.gca()\n",
        "    axes.set_ylim([ylim, 1])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    train_sizes = np.arange(1, 1 + len(history[0].history['accuracy']))\n",
        "    plt.ylim((0,1))\n",
        "    plt.grid()\n",
        "    plt.plot(\n",
        "        train_sizes,\n",
        "        history[0].history['accuracy'],\n",
        "        'o-',\n",
        "        color=(177/255, 6/255, 58/255),\n",
        "        label=\"scce\"\n",
        "    )\n",
        "    plt.plot(\n",
        "        train_sizes,\n",
        "        history[1].history['accuracy'],\n",
        "        'o-',\n",
        "        color=(246/255, 168/255, 0),\n",
        "        label=\"mse\")\n",
        "    \n",
        "    plt.plot(\n",
        "        train_sizes,\n",
        "        history[2].history['accuracy'],\n",
        "        'o-',\n",
        "        color='green',\n",
        "        label=\"cce\"\n",
        "    )\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "plot_learning_curve()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96qK4pQhNFMG",
        "colab_type": "text"
      },
      "source": [
        "- scce = Sparse Categorical Crossentropy\n",
        "- cce = Categorical Crossentropy\n",
        "- mse = Mean Squared Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvRsmWsOFb-K",
        "colab_type": "text"
      },
      "source": [
        "# Wann sollte man CategoricalCross Entropy nutzen und wann Sparse Categorical Crossentropy?\n",
        "\n",
        "für `Categorical Cross Entropy` müssen die Labels als Array mit einer 1 am Index der zugehören Klasse vorliegen.\n",
        "\n",
        "\n",
        "für `Sparse Categorical Cross Entropy` müssen die Labels mit Bezeichnung der Ausgangsklasse vorliegen.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK5EupCgf1uP",
        "colab_type": "code",
        "outputId": "96c6f029-0cbd-475d-ab4b-d906db2b7711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "_test_labels = keras.utils.to_categorical(test_labels, 10)\n",
        "\n",
        "print('Test labels categorical:')\n",
        "print(_test_labels[:2])\n",
        "print('Verwendung der categorical_crossentropy gefordert')\n",
        "print('\\n')\n",
        "print('Test labels non categorical:')\n",
        "print(test_labels[:2])\n",
        "print('Verwendung der sparse_categorical_crossentropy gefordert')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test labels categorical:\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Verwendung der categorical_crossentropy gefordert\n",
            "\n",
            "\n",
            "Test labels non categorical:\n",
            "[7 2]\n",
            "Verwendung der sparse_categorical_crossentropy gefordert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg6Ct_aINTfB",
        "colab_type": "text"
      },
      "source": [
        "Umwandlung in Categorical Werte:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCkmlbg2GMSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_test_labels = keras.utils.to_categorical(train_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}