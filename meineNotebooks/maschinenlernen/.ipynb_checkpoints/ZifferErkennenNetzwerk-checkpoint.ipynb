{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quelle:](https://rolisz.ro/2013/04/18/neural-networks-in-python/ \"hier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# die Aktivierungsfunktion und ihre erste Ableitung\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def tanh_prime(x):\n",
    "    return 1.0-np.tanh(x)**2\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, activation='tanh'):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_prime\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_prime\n",
    "        # Set weights\n",
    "        self.layers=layers\n",
    "        self.weights = []        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1            \n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "        \n",
    "    def bestimmeGewichte(self,wert):\n",
    "        self.weights=[]\n",
    "        layers=self.layers\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = np.zeros((layers[i-1] + 1, layers[i] + 1)) +wert\n",
    "            #print(i,r)\n",
    "            self.weights.append(r)\n",
    "        r = np.zeros( (layers[i] + 1, layers[i+1])) +wert\n",
    "        self.weights.append(r)\n",
    "        print(\"feste Gewichte\\n\",self.weights,self.weights[1].shape)\n",
    "        \n",
    "    def prepareInput(self,inListe):\n",
    "        # setzt eine Spalte mit Einsen als Bias vor die Eingabe\n",
    "        eingabe=inListe#np.array(inListe)\n",
    "        X        = np.ones((len(eingabe),len(eingabe[0])+1))\n",
    "        X[:,1:] = eingabe\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):        \n",
    "        self.fehler=0        \n",
    "        for k in range(epochs):                \n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]            \n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)                    \n",
    "                    a.append(activation)                    \n",
    "            error = y[i] - a[-1]\n",
    "            self.fehler+=np.sum(np.square(error)) #Summe der Quadrate     \n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()            \n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer=np.array(a[i])\n",
    "                layer=layer[:,None] #Umwandeln in eine nx1 Matrix \n",
    "                delta=np.array(deltas[i])\n",
    "                delta=delta[None,:] #Umwandeln in eine 1xn-Matrix               \n",
    "                self.weights[i]+=learning_rate*np.dot(layer,delta)\n",
    "            \n",
    "\n",
    "    def predict(self, x):        \n",
    "        for l in range(0, len(self.weights)):\n",
    "            x = self.activation(np.dot(x, self.weights[l]))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  0  0  0  1  0  2  0  1  1]\n",
      " [ 0 26  0  0  0  2  3  0 10  1]\n",
      " [ 0  3 32  1  0  2  2  0  2  0]\n",
      " [ 0  0  1 31  0  3  4  0  3  1]\n",
      " [ 0  0  0  0 43  0  1  3  0  0]\n",
      " [ 0  0  0  0  0 49  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 44  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 42  0  0]\n",
      " [ 0  0  0  0  0  4  4  0 35  1]\n",
      " [ 1  0  0  0  0  1  2  2  1 38]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.90      0.94        49\n",
      "          1       0.90      0.62      0.73        42\n",
      "          2       0.97      0.76      0.85        42\n",
      "          3       0.97      0.72      0.83        43\n",
      "          4       0.98      0.91      0.95        47\n",
      "          5       0.80      0.96      0.88        51\n",
      "          6       0.70      0.98      0.81        45\n",
      "          7       0.89      1.00      0.94        42\n",
      "          8       0.66      0.80      0.72        44\n",
      "          9       0.88      0.84      0.86        45\n",
      "\n",
      "avg / total       0.87      0.85      0.85       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "#from NeuralNetwork import NeuralNetwork\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X -= X.min() # normalize the values to bring them into the range 0-1\n",
    "X /= X.max()\n",
    "\n",
    "nn = NeuralNetwork([64,100,10])\n",
    "X=nn.prepareInput(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "labels_train = LabelBinarizer().fit_transform(y_train)\n",
    "labels_test = LabelBinarizer().fit_transform(y_test)\n",
    "\n",
    "nn.fit(X_train,labels_train,epochs=30000)\n",
    "predictions = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    o = nn.predict(X_test[i] )\n",
    "    predictions.append(np.argmax(o))\n",
    "print (confusion_matrix(y_test,predictions))\n",
    "print (classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
