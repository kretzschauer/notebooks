{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Trainingsdaten: (60000, 28, 28)\n",
      "Dimension Bild Nr. 5: (28, 28)\n",
      "Label zu Bild Nr. 5: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "test_labels_ori = test_labels\n",
    "\n",
    "print(\"Shape Trainingsdaten: {}\".format(train_images.shape))\n",
    "print(\"Dimension Bild Nr. 5: {}\".format(train_images[5].shape))\n",
    "print(\"Label zu Bild Nr. 5: {}\".format(train_labels[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdatensatz:(60000, 28, 28, 1)\n",
      "Testdatensatz:(10000, 28, 28, 1)\n",
      "Wir haben 60000 Trainingsbilder und 10000 Testbilder.\n"
     ]
    }
   ],
   "source": [
    "NrTrainimages = train_images.shape[0]\n",
    "NrTestimages = test_images.shape[0]\n",
    "\n",
    "print(\"Trainingsdatensatz:{}\".format(train_images.shape))\n",
    "print(\"Testdatensatz:{}\".format(test_images.shape))\n",
    "\n",
    "print(\"Wir haben {} Trainingsbilder und {} Testbilder.\".format(NrTrainimages, NrTestimages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAEXCAYAAAC+tLGPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf35e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "randindex = random.randint(0,60000)\n",
    "plttitle = \"Trainingsbild Nr. {} \\n Klasse: {}\".format(randindex,train_labels[randindex])\n",
    "plt.imshow(train_images[randindex].reshape(28,28), cmap='gray')\n",
    "plt.title(plttitle)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_inputshape = train_images[0].shape\n",
    "mnist_inputshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = r\"D:/logs\"\n",
    "LOGDIR = os.path.join(basedir,\"tb_logs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensorboard = TensorBoard(log_dir = LOGDIR,\n",
    "                             histogram_freq=0,\n",
    "                            write_graph=True,\n",
    "                            write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 192,202\n",
      "Trainable params: 192,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5,5), \n",
    "                activation = 'relu',\n",
    "                input_shape=mnist_inputshape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5,5),activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', name='features'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_batch_size = 128\n",
    "my_num_classes = 10\n",
    "my_epochs = 12\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='Adam',\n",
    "             metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.3730 - acc: 0.8801 - val_loss: 0.0554 - val_acc: 0.9831\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.1082 - acc: 0.9675 - val_loss: 0.0363 - val_acc: 0.9888\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0796 - acc: 0.9767 - val_loss: 0.0316 - val_acc: 0.9904\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0667 - acc: 0.9804 - val_loss: 0.0280 - val_acc: 0.9916\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0620 - acc: 0.9820 - val_loss: 0.0289 - val_acc: 0.9903\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0536 - acc: 0.9839 - val_loss: 0.0226 - val_acc: 0.9925\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0490 - acc: 0.9855 - val_loss: 0.0194 - val_acc: 0.9939\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0444 - acc: 0.9867 - val_loss: 0.0202 - val_acc: 0.9939\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0433 - acc: 0.9868 - val_loss: 0.0201 - val_acc: 0.9935\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0406 - acc: 0.9882 - val_loss: 0.0207 - val_acc: 0.9931\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0379 - acc: 0.9882 - val_loss: 0.0241 - val_acc: 0.9926\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0358 - acc: 0.9889 - val_loss: 0.0207 - val_acc: 0.9940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,train_labels,\n",
    "         batch_size=my_batch_size,\n",
    "         callbacks=[my_tensorboard],\n",
    "         epochs=my_epochs,\n",
    "         verbose=1,\n",
    "         validation_data=(test_images,test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1510e860>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 650us/step\n",
      "Test Verlust: 0.0206829725912\n",
      "Test Genauigkeit: 0.994\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels)\n",
    "print('Test Verlust:', score[0])\n",
    "print('Test Genauigkeit:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
