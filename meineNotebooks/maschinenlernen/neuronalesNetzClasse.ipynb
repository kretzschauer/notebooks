{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronales Netz\n",
    "Quelle: [BogoToBogo](https://www.bogotobogo.com/python/python_Neural_Networks_Backpropagation_for_XOR_using_one_hidden_layer.php), mit vielen Tutorials zu Python\n",
    "\n",
    "Außerdem [hier](http://pandamatak.com/people/anand/771/html/node37.html) Erläuterungen zum Backpropagation-Algorithmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# die Aktivierungsfunktion und ihre erste Ableitung\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def tanh_abl(x):\n",
    "    return 1.0-np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Aktivierungsfunktion ist hier $f(x)= \\tanh x =  \\frac{sinh(x)}{cosh(x)}= \\frac{e^x -e^{-x}}{e^x + e^{-x}}=1-\\frac{2}{e^{2x}+1}$  gewählt, weil es die besten Lern-Ergebnisse  lieferte. Im Bild sieht man grün die Funktion und blau die Ableitungsfunktion $f'(x)= 1- f(x)² $. NACHRECHNEN! ![Aktivierungsfunktionen tanh](images/aktivierungsfunktionen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spezielles Netzwerk für XOR mit zwei Eingaben, einer Ausgabe und einer versteckten Schicht mit zwei Knoten: Layers = [2,2,1].\n",
    "In der Quelle ist das Programm allgemeiner dargestellt, so dass es für andere Netze angewendet werden kann.\n",
    "![Bild vom Netzwerk](images/NeuralNetworksDiagram00.png)\n",
    "\n",
    "\n",
    "Die Korrektur der Gewichte mittels Backpropagation ist gut auf [Wikipedia](https://de.wikipedia.org/wiki/Backpropagation \"Wikipedia\") beschrieben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronalNetwork:\n",
    "    def __init__(self):\n",
    "        layers=[2,2,1]\n",
    "        self.weights=[] #Gewichte zufaellig festlegen\n",
    "        w=2*np.random.random((3,3))-1 #liegen zwischen -1 und 1\n",
    "        self.weights.append(w)\n",
    "        w=2*np.random.random((3,1))-1\n",
    "        self.weights.append(w)\n",
    "        self.fehler=0\n",
    "        \n",
    "    def prepareInput(self,inListe):\n",
    "        # setzt eine Spalte mit Einsen als Bias vor die Eingabe\n",
    "        eingabe=np.array(inListe)\n",
    "        X        = np.ones((len(eingabe),len(eingabe[0])+1))\n",
    "        X[:,1:] = eingabe\n",
    "        print (X)\n",
    "        return X\n",
    "        \n",
    "    def fit(self,X,y,lernrate=0.1,epoches=1000):\n",
    "        for k in range(epoches):\n",
    "            i=np.random.randint(X.shape[0])#zufaellig eine Eingabe waehlen\n",
    "            a=[X[i]] # eine Liste der Ausgaben der einzelnen Schichten \n",
    "            for j in range(len(self.weights)):\n",
    "                hidden_in  = np.dot(a[j],self.weights[j]) # Eingabe mal Gewichte\n",
    "                hidden_out = tanh(hidden_in)              # Aktivierungsfunktion\n",
    "                a.append(hidden_out)                      # anhaengen an die Liste\n",
    "            error  = y[i]-a[-1]\n",
    "            self.fehler +=np.sum(np.square(error))  #zur Kontrolle der quadr. Fehler   \n",
    "            # Backpropagation, Fehler berechnen und an die Fehlerliste anhaengen\n",
    "            deltas = [error * tanh_abl(a[-1])] #Fehler der Ausgabeschicht\n",
    "            for j in range(len(a)-2,0,-1):\n",
    "                deltas.append(deltas[-1].dot(self.weights[j].T)*tanh_abl(a[j]))\n",
    "                # Fehleranteile der vorherigen Schichten\n",
    "            deltas.reverse()            \n",
    "            # Korrektur der Gewichte \n",
    "            for i in range(len(self.weights)):\n",
    "                layer=np.array(a[i])\n",
    "                layer=layer[:,None]#Umwandeln in eine nx1 Matrix \n",
    "                delta=np.array(deltas[i])\n",
    "                delta=delta[None,:]#Umwandeln in eine 1xn-Matrix               \n",
    "                self.weights[i]+=lernrate*np.dot(layer,delta)\n",
    "          \n",
    "    def predict(self,x):      \n",
    "        for i in range(len(self.weights)):\n",
    "            x=tanh(np.dot(x,self.weights[i]))            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 1.]]\n",
      "1\n",
      "[0. 0.] [0.40970512]\n",
      "[0. 1.] [0.49440553]\n",
      "[1. 0.] [0.42624589]\n",
      "[1. 1.] [0.48831048]\n",
      "29.013017180938164\n",
      "\n",
      "2\n",
      "[0. 0.] [0.47970861]\n",
      "[0. 1.] [0.47115441]\n",
      "[1. 0.] [0.56937753]\n",
      "[1. 1.] [0.52778603]\n",
      "25.588802294498926\n",
      "\n",
      "3\n",
      "[0. 0.] [0.53068935]\n",
      "[0. 1.] [0.48239884]\n",
      "[1. 0.] [0.61294021]\n",
      "[1. 1.] [0.51054604]\n",
      "24.83904746627341\n",
      "\n",
      "4\n",
      "[0. 0.] [0.58919265]\n",
      "[0. 1.] [0.57285064]\n",
      "[1. 0.] [0.64011024]\n",
      "[1. 1.] [0.55024755]\n",
      "23.038517410835734\n",
      "\n",
      "5\n",
      "[0. 0.] [0.5870239]\n",
      "[0. 1.] [0.63867766]\n",
      "[1. 0.] [0.68136016]\n",
      "[1. 1.] [0.62660668]\n",
      "22.44223015179765\n",
      "\n",
      "6\n",
      "[0. 0.] [0.32723775]\n",
      "[0. 1.] [0.53407173]\n",
      "[1. 0.] [0.47839322]\n",
      "[1. 1.] [0.34448206]\n",
      "22.102195181819052\n",
      "\n",
      "7\n",
      "[0. 0.] [0.2816829]\n",
      "[0. 1.] [0.51486008]\n",
      "[1. 0.] [0.66620405]\n",
      "[1. 1.] [0.3697473]\n",
      "16.633740824543633\n",
      "\n",
      "8\n",
      "[0. 0.] [0.06890852]\n",
      "[0. 1.] [0.62359543]\n",
      "[1. 0.] [0.58409192]\n",
      "[1. 1.] [0.22817688]\n",
      "12.289653323400914\n",
      "\n",
      "9\n",
      "[0. 0.] [0.18267473]\n",
      "[0. 1.] [0.77169923]\n",
      "[1. 0.] [0.65295537]\n",
      "[1. 1.] [0.16939641]\n",
      "7.873713315850853\n",
      "\n",
      "10\n",
      "[0. 0.] [0.16483125]\n",
      "[0. 1.] [0.78344675]\n",
      "[1. 0.] [0.77131966]\n",
      "[1. 1.] [0.11974646]\n",
      "4.834323831733908\n",
      "\n",
      "11\n",
      "[0. 0.] [0.21476448]\n",
      "[0. 1.] [0.85168935]\n",
      "[1. 0.] [0.84974839]\n",
      "[1. 1.] [0.30351279]\n",
      "3.203202253350241\n",
      "\n",
      "12\n",
      "[0. 0.] [0.03902704]\n",
      "[0. 1.] [0.82531282]\n",
      "[1. 0.] [0.86370617]\n",
      "[1. 1.] [0.06263229]\n",
      "1.840507861310613\n",
      "\n",
      "13\n",
      "[0. 0.] [0.02850367]\n",
      "[0. 1.] [0.84830359]\n",
      "[1. 0.] [0.88703132]\n",
      "[1. 1.] [0.05315799]\n",
      "1.2291557365979182\n",
      "\n",
      "14\n",
      "[0. 0.] [0.0409372]\n",
      "[0. 1.] [0.87228889]\n",
      "[1. 0.] [0.91407141]\n",
      "[1. 1.] [0.09730921]\n",
      "1.1763850283088069\n",
      "\n",
      "15\n",
      "[0. 0.] [0.04678396]\n",
      "[0. 1.] [0.90800204]\n",
      "[1. 0.] [0.90165222]\n",
      "[1. 1.] [0.02155491]\n",
      "0.6787245380533246\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(0)#liefert reproduzierbare Ergebnisse\n",
    "\n",
    "nn=NeuronalNetwork()\n",
    "#Eingabevektor, die Vorbereitung erfolgt in einer Extra -Funktion des Netzes\n",
    "eingabe=[[0, 0], [0, 1],[1, 0], [1, 1]]\n",
    "#Die Ziel-Ausgabe\n",
    "y = np.array([0, 1, 1, 0])\n",
    "X=nn.prepareInput(eingabe)\n",
    "#Test des Netzes\n",
    "for i in range(20):\n",
    "    print(i+1)\n",
    "    nn.fit(X,y,0.1,100)\n",
    "    for e in X:\n",
    "        print(e[1:],nn.predict(e))\n",
    "    print(nn.fehler)\n",
    "    if nn.fehler<1:\n",
    "        break\n",
    "    nn.fehler=0\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
