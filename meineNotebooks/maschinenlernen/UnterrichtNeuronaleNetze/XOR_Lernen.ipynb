{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "healthy-glance",
   "metadata": {},
   "source": [
    "# Netz zum Lernen von XOR\n",
    "## Initialisierung\n",
    "2 Eingaben und BIAS, 5 Neuronen in der Hidden Schicht und ein Ausgabeneuron\n",
    "<img src=\"bilder/netzarchitektur.png\"  width=\"360\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "respected-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gewichte:\n",
      " [[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "HiddenIn: \n",
      " [[1. 1. 1. 1. 1.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 3.]]\n",
      "Hidden act:\n",
      " [[0.26894142 0.26894142 0.26894142 0.26894142 0.26894142]\n",
      " [0.11920292 0.11920292 0.11920292 0.11920292 0.11920292]\n",
      " [0.11920292 0.11920292 0.11920292 0.11920292 0.11920292]\n",
      " [0.04742587 0.04742587 0.04742587 0.04742587 0.04742587]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x, deriv = False):\n",
    "    if deriv == True:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([[0, 0, 1],[0, 1, 1],[1, 0, 1],[1, 1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]   ])\n",
    "nr=0\n",
    "wIH = np.ones((len(X[0]), 5)) #eine Eingabe aus den vieren \n",
    "print(\"Gewichte:\\n\",wIH)\n",
    "wHO = np.ones((5, 1))\n",
    "HI=np.dot(X,wIH)\n",
    "print(\"HiddenIn: \\n\",HI)\n",
    "H_act =sigmoid(-HI)\n",
    "print(\"Hidden act:\\n\",H_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "german-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OutIn:\n",
      " [[1.34470711]\n",
      " [0.59601461]\n",
      " [0.59601461]\n",
      " [0.23712937]]\n",
      "OutAct:\n",
      " [[0.20673704]\n",
      " [0.35525602]\n",
      " [0.35525602]\n",
      " [0.44099389]]\n",
      "Fehler Out:\n",
      " [[0.0213701 ]\n",
      " [0.2078474 ]\n",
      " [0.2078474 ]\n",
      " [0.09723781]]\n"
     ]
    }
   ],
   "source": [
    "O_In=np.dot(H_act,wHO)\n",
    "print(\"OutIn:\\n\",O_In)\n",
    "O_act=sigmoid(-O_In)\n",
    "print(\"OutAct:\\n\",O_act)\n",
    "O_error = ((1 / 2) * (np.power((O_act - y), 2)))\n",
    "print(\"Fehler Out:\\n\",O_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-editor",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "Aus dem Fehler wird die Korrektur der Gewichte berechnet.\n",
    "\n",
    "https://towardsdatascience.com/understanding-neural-networks-what-how-and-why-18ec703ebd31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "distinguished-calgary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.01681234 1.72407211]\n",
      " [1.81226166 1.1929248 ]\n",
      " [1.41207495 1.98180837]]\n",
      "[[1.52486824]\n",
      " [1.24188552]]\n",
      "[[1.01616019 1.72370856]\n",
      " [1.8113412  1.19262652]\n",
      " [1.39379673 1.97181179]]\n",
      "[[1.4200206 ]\n",
      " [1.13135636]]\n",
      "[[0.99728133 1.71578551]\n",
      " [1.78312107 1.17650885]\n",
      " [1.41013513 1.88850854]]\n",
      "[[ 0.03079097]\n",
      " [-0.0879398 ]]\n",
      "[[0.98572408 1.71914947]\n",
      " [1.77056686 1.17588081]\n",
      " [1.45894448 1.84850981]]\n",
      "[[ 0.06648722]\n",
      " [-0.05241984]]\n",
      "[[0.9349293  1.72763422]\n",
      " [1.77658049 1.16743672]\n",
      " [1.42235812 1.8507843 ]]\n",
      "[[ 0.22419176]\n",
      " [-0.20142168]]\n",
      "[[0.49563247]\n",
      " [0.49387306]\n",
      " [0.49252539]\n",
      " [0.49708699]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x, deriv = False):\n",
    "    if deriv == True:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([[0, 0, 1],[0, 1, 1],[1, 0, 1],[1, 1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]   ])\n",
    "anz_H=2\n",
    "syn0 = 2+np.random.random((3,anz_H)) -1\n",
    "syn1 = 2+np.random.random((anz_H,1)) -1\n",
    "print(syn0)\n",
    "print(syn1)\n",
    "\n",
    "#For loop iterate over the training set\n",
    "for i in range(4000):    \n",
    "    #First layer is the input    \n",
    "    l0 = X    \n",
    "    #Second layer can be obtained with the multiplication of each layer \n",
    "    #and its synapsis and then running sigmoid function \n",
    "    l1 = sigmoid(np.dot(l0, syn0))    \n",
    "    #Do the same with l1 and its synapsis \n",
    "    l2 = sigmoid(np.dot(l1,syn1))\n",
    "        #Compute the error by checking how far the prediction \n",
    "    #is from the real value.\n",
    "    l2_error = y - l2\n",
    "    #multiply error rate by result of sigmoide on l2 to get derivative\n",
    "    #from output\n",
    "    #Delta will be use to reduce error rate of prediction when update syn     \n",
    "    #FORMULA 1\n",
    "    l2_delta = l2_error*sigmoid(l2, deriv=True)    \n",
    "    #How much l1 contributed to error in l2. Multiply\n",
    "    #layer2_delta with syn1 transpose. \n",
    "    l1_error = l2_delta.dot(syn1.T)    \n",
    "    #get delta for l1 \n",
    "    l1_delta = l1_error * sigmoid(l1, deriv=True)    \n",
    "    #Update our synapse rates to reduce the error rate every iteration\n",
    "    #Multiply each layer by a delta    \n",
    "    #*BACKPROPAGATION*\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(syn0)\n",
    "        print(syn1)\n",
    "l1 = sigmoid(np.dot(l0, syn0))    \n",
    "#Do the same with l1 and its synapsis \n",
    "l2 = sigmoid(np.dot(l1,syn1))\n",
    "#Compute the error by checking how far the prediction \n",
    "#is from the real value.\n",
    "l2_error = y - l2\n",
    "print(l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-frequency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
