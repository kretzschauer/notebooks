{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777df850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d97ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nummer</th>\n",
       "      <th>Auge_li</th>\n",
       "      <th>Auge_re</th>\n",
       "      <th>Mund</th>\n",
       "      <th>Beschriftung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>Zahn</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>offen</td>\n",
       "      <td>offen</td>\n",
       "      <td>Grinsen</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>zu</td>\n",
       "      <td>zu</td>\n",
       "      <td>Grinsen</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>grimmig</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>weit offen</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nummer Auge_li Auge_re        Mund Beschriftung\n",
       "0       3       x       x        Zahn            B\n",
       "1       5   offen   offen     Grinsen            B\n",
       "2       8      zu      zu     Grinsen            B\n",
       "3      11       x       x     grimmig            B\n",
       "4      15       x       x  weit offen            B"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#diese Daten müssen an den Datensatz angepast werden\n",
    "train=\"data/affen2train.csv\"\n",
    "test=\"data/affen2test.csv\"\n",
    "spalten=[\"Nummer\",\"Auge_li\",\"Auge_re\",\"Mund\",\"Beschriftung\"]\n",
    "#train=\"data/PlayTennisTrain.csv\"\n",
    "#test=\"data/PlayTennisTest.csv\"\n",
    "#spalten=[0,1,2,3,4,5]\n",
    "sep=';'\n",
    "label=\"Beschriftung\"\n",
    "train_data_m = pd.read_csv(train,sep=sep,usecols=spalten)\n",
    "train_data_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc068eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'BN'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=train_data_m.copy()\n",
    "class_list = train_data[label].unique()\n",
    "class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65020f",
   "metadata": {},
   "source": [
    "Für alle Attribute (Auge_li, Auge_re, Mund) muss der Informationsgewinn Gain(A,S) berechnet werden. Das ist der Wert, der die Reduzierung der Unsicherheit (Entropie) beschreibt, wenn man den Wert von A kennt. \n",
    "\n",
    "$$ Gain(S,A) = H(S) - \\sum_{v \\in  A} \\frac{|S_v|}{|S|} H(S_v)$$\n",
    "S   : Datensatz  \n",
    "H(S): Entropie des Datensatz  \n",
    "$S_v$ : Teilmenge von S für den A den Wert v hat   \n",
    "|S| : Mächtigkeit von S  \n",
    "$|S_v|$: Mächtigkeit von $S_v$\n",
    "So berechnet man die Entropie H(S)  \n",
    "$$ H(S) = -\\sum_{c=1}^{|C|} p_clog_2 p_c$$\n",
    "|C|  : Anzahl der Kategorien  \n",
    "$p_c$: Anteil der Instanzen in S, die der Kategorie c angehören"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac07f99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtentropie: 0.9852281360342515\n"
     ]
    }
   ],
   "source": [
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0    \n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n",
    "        #row count of class c \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count #probability of the class\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
    "        entropy += entropy_class\n",
    "    return entropy\n",
    "total_entropy=calc_entropy(train_data, label, class_list)#Gesamtentropie\n",
    "print(\"Gesamtentropie:\", total_entropy)\n",
    "\n",
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0    \n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "        #Zeilen auswählen mit feature_value\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list)\n",
    "        #calculcating entropy for the feature value\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy\n",
    "        #aufaddieren\n",
    "    info_gain=    calc_entropy(train_data, label, class_list) - feature_info\n",
    "    print(feature_name,info_gain)\n",
    "    return info_gain\n",
    "        #calculating information gain by subtracting\n",
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    feature_list = train_data.columns.drop(label)\n",
    "    #finding the feature names in the dataset\n",
    "    #N.B. label is not a feature, so dropping it\n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None    \n",
    "    for feature in feature_list:  #for each feature in the dataset\n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "        if max_info_gain < feature_info_gain:\n",
    "            #selecting feature name with highest information gain\n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature  \n",
    "    print(max_info_feature)\n",
    "    return max_info_feature\n",
    "#find_most_informative_feature(train_data,label,class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca4b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nummer 0.9852281360342515\n",
      "Auge_li 0.49261406801712576\n",
      "Auge_re 0.49261406801712576\n",
      "Mund 0.19811742113040343\n",
      "Nummer\n",
      "der Baum {'Nummer': {3: 'B', 5: 'B', 8: 'B', 11: 'B', 15: 'B', 19: 'B', 1: 'BN', 2: 'BN', 10: 'BN', 12: 'BN', 13: 'BN', 14: 'BN', 18: 'BN', 20: 'BN'}}\n",
      "richtig:  0   falsch:  6\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False)\n",
    "    #dictionary of the count of unqiue feature value\n",
    "    tree = {} #sub tree or node\n",
    "    \n",
    "    for feature_value, count in feature_value_count_dict.iteritems():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "        #dataset with only feature_name = feature_value\n",
    "        \n",
    "        assigned_to_node = False #flag for tracking feature_value is pure class or not\n",
    "        for c in class_list: #for each class\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n",
    "            #count of class c\n",
    "\n",
    "            if class_count == count: #count of feature_value = count of class (pure class)\n",
    "                tree[feature_value] = c #adding node to the tree\n",
    "                train_data = train_data[train_data[feature_name] != feature_value]\n",
    "                #removing rows with feature_value\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node: #not pure class\n",
    "            tree[feature_value] = \"?\" #should extend the node, so the branch is marked with ?\n",
    "            \n",
    "    return tree, train_data\n",
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0: #if dataset becomes enpty after updating\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list)\n",
    "        #most informative feature\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list)\n",
    "        #getting tree node and updated dataset\n",
    "        next_root = None\n",
    "        \n",
    "        if prev_feature_value != None: #add to intermediate node of the tree\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else: #add to root of the tree\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "        \n",
    "        for node, branch in list(next_root.items()): #iterating the tree node\n",
    "            if branch == \"?\": #if it is expandable\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node]\n",
    "                #using the updated dataset\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list)\n",
    "                #recursive call with updated dataset\n",
    "\n",
    "def id3(train_data_m, label):\n",
    "    train_data = train_data_m.copy() #getting a copy of the dataset\n",
    "    tree = {} #tree which will be updated\n",
    "    class_list = train_data[label].unique() #getting unqiue classes of the label\n",
    "    make_tree(tree, None, train_data_m, label, class_list) #start calling recursion\n",
    "    return tree\n",
    "tree=id3(train_data,label)\n",
    "print(\"der Baum\",tree)\n",
    "\n",
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict): #if it is leaf node\n",
    "        return tree #return the value\n",
    "    else:\n",
    "        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\n",
    "        feature_value = instance[root_node] #value of the feature\n",
    "        if feature_value in tree[root_node]: #checking the feature value in current tree node\n",
    "            return predict(tree[root_node][feature_value], instance) #goto next feature\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def evaluate(tree, test_data_m, label):\n",
    "    correct_preditct = 0\n",
    "    wrong_preditct = 0\n",
    "    for index, row in test_data_m.iterrows(): #for each row in the dataset\n",
    "        result = predict(tree, test_data_m.iloc[index]) #predict the row\n",
    "        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\n",
    "            correct_preditct += 1 #increase correct count\n",
    "        else:\n",
    "            wrong_preditct += 1 #increase incorrect count\n",
    "    print(\"richtig: \",correct_preditct,\"  falsch: \",wrong_preditct )\n",
    "    accuracy = correct_preditct / (correct_preditct + wrong_preditct) #calculating accuracy\n",
    "    return accuracy\n",
    "\n",
    "test_data_m = pd.read_csv(test,sep=sep,usecols=spalten)\n",
    "#importing test dataset into dataframe\n",
    "accuracy = evaluate(tree, test_data_m, label) #evaluating the test dataset\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f2dbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
